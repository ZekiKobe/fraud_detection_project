{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491ccaa3",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "445f7ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fraud_data_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Apply feature engineering\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m fraud_data_fe = engineer_fraud_features(\u001b[43mfraud_data_clean\u001b[49m, ip_country)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# For credit data, features are already engineered (V1-V28 from PCA)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Just separate features and target\u001b[39;00m\n\u001b[32m     31\u001b[39m X_credit = credit_data_clean.drop(\u001b[33m'\u001b[39m\u001b[33mClass\u001b[39m\u001b[33m'\u001b[39m, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'fraud_data_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature engineering for fraud data\n",
    "def engineer_fraud_features(df, ip_country):\n",
    "    # Convert IP to integer and merge with country data\n",
    "    df['ip_address'] = df['ip_address'].apply(lambda x: int(x.replace('.', '')))\n",
    "    \n",
    "    # Merge with country data\n",
    "    for index, row in ip_country.iterrows():\n",
    "        mask = (df['ip_address'] >= row['lower_bound_ip_address']) & (df['ip_address'] <= row['upper_bound_ip_address'])\n",
    "        df.loc[mask, 'country'] = row['country']\n",
    "    \n",
    "    # Time-based features\n",
    "    df['hour_of_day'] = df['purchase_time'].dt.hour\n",
    "    df['day_of_week'] = df['purchase_time'].dt.dayofweek\n",
    "    df['time_since_signup'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Transaction velocity (would need more data for proper implementation)\n",
    "    # For now, we'll calculate purchases per user\n",
    "    user_counts = df['user_id'].value_counts().to_dict()\n",
    "    df['user_transaction_count'] = df['user_id'].map(user_counts)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    df = pd.get_dummies(df, columns=['source', 'browser', 'sex', 'country'], drop_first=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "fraud_data_fe = engineer_fraud_features(fraud_data_clean, ip_country)\n",
    "\n",
    "# For credit data, features are already engineered (V1-V28 from PCA)\n",
    "# Just separate features and target\n",
    "X_credit = credit_data_clean.drop('Class', axis=1)\n",
    "y_credit = credit_data_clean['Class']\n",
    "\n",
    "# Save engineered data\n",
    "fraud_data_fe.to_csv('../data/processed/fraud_data_fe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
