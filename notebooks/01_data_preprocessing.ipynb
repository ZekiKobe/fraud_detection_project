{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590edde6",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2f8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Load datasets\n",
    "fraud_data = pd.read_csv('../data/raw/Fraud_Data.csv')\n",
    "ip_country = pd.read_csv('../data/raw/IpAddress_to_Country.csv')\n",
    "credit_data = pd.read_csv('../data/raw/creditcard.csv')\n",
    "\n",
    "# Data cleaning functions\n",
    "def clean_fraud_data(df):\n",
    "    # Handle missing values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Convert timestamps\n",
    "    df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
    "    df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_credit_data(df):\n",
    "    # No missing values in this dataset\n",
    "    # Scale the 'Amount' feature\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply cleaning\n",
    "fraud_data_clean = clean_fraud_data(fraud_data)\n",
    "credit_data_clean = clean_credit_data(credit_data)\n",
    "\n",
    "# Save cleaned data\n",
    "fraud_data_clean.to_csv('../data/processed/fraud_data_clean.csv', index=False)\n",
    "credit_data_clean.to_csv('../data/processed/credit_data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a703141c",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf506f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_fraud_features(df, ip_country):\n",
    "    # First ensure IP addresses are strings and handle missing values\n",
    "    df['ip_address'] = df['ip_address'].astype(str)\n",
    "    \n",
    "    # Remove any rows where IP is 'nan' (from NaN values)\n",
    "    df = df[df['ip_address'] != 'nan']\n",
    "    \n",
    "    # Convert valid IPs to integer format\n",
    "    df['ip_address'] = df['ip_address'].apply(lambda x: int(x.replace('.', '')) if x != 'nan' else None)\n",
    "    \n",
    "    # Drop any remaining rows with null IPs after conversion\n",
    "    df = df.dropna(subset=['ip_address'])\n",
    "    \n",
    "    # Merge with country data (optimized version)\n",
    "    ip_country['lower_bound'] = ip_country['lower_bound_ip_address'].astype('int64')\n",
    "    ip_country['upper_bound'] = ip_country['upper_bound_ip_address'].astype('int64')\n",
    "    \n",
    "    # Create country mapping using interval indexing (more efficient than row-by-row)\n",
    "    country_map = []\n",
    "    for _, row in ip_country.iterrows():\n",
    "        country_map.append((row['lower_bound'], row['upper_bound'], row['country']))\n",
    "    \n",
    "    def find_country(ip_int):\n",
    "        for lower, upper, country in country_map:\n",
    "            if lower <= ip_int <= upper:\n",
    "                return country\n",
    "        return None\n",
    "    \n",
    "    df['country'] = df['ip_address'].apply(find_country)\n",
    "    \n",
    "    # Drop rows where country couldn't be determined\n",
    "    df = df.dropna(subset=['country'])\n",
    "    \n",
    "    # Time-based features\n",
    "    df['hour_of_day'] = df['purchase_time'].dt.hour\n",
    "    df['day_of_week'] = df['purchase_time'].dt.dayofweek\n",
    "    df['time_since_signup'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Transaction velocity features\n",
    "    user_counts = df['user_id'].value_counts().to_dict()\n",
    "    df['user_transaction_count'] = df['user_id'].map(user_counts)\n",
    "    \n",
    "    # Time between transactions (requires sorting)\n",
    "    df = df.sort_values(['user_id', 'purchase_time'])\n",
    "    df['time_since_last_transaction'] = df.groupby('user_id')['purchase_time'].diff().dt.total_seconds() / 3600\n",
    "    \n",
    "    # Encode categorical features\n",
    "    df = pd.get_dummies(df, \n",
    "                       columns=['source', 'browser', 'sex', 'country'], \n",
    "                       drop_first=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "fraud_data_fe = engineer_fraud_features(fraud_data_clean, ip_country)\n",
    "\n",
    "# For credit data, features are already engineered (V1-V28 from PCA)\n",
    "# Just separate features and target\n",
    "X_credit = credit_data_clean.drop('Class', axis=1)\n",
    "y_credit = credit_data_clean['Class']\n",
    "\n",
    "# Save engineered data\n",
    "fraud_data_fe.to_csv('../data/processed/fraud_data_fe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
